{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fmin_tnc\n",
    "import random\n",
    "\n",
    "def read_file(filename):\n",
    "    return pd.read_csv(filename)\n",
    "\n",
    "#read_file(\"data/petrol_consumption.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    mean = np.mean(data)\n",
    "    st = np.std(data)\n",
    "    return (data - mean)/st   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X, theta):\n",
    "    #return 1.0/ (1 + np.exp(-(np.dot(X, theta))))\n",
    "    return np.divide(1.0, 1 + np.exp(-np.matmul(X, theta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost_function(X, y, theta):\n",
    "    m = X.shape[0]\n",
    "    pred = sigmoid(X, theta)\n",
    "    cross_entropy = np.sum( (y * np.log(pred)) + ((1-y) * np.log(1-pred)) )\n",
    "    #print(\"1: \",np.dot(y.T, np.log(pred)))\n",
    "    #print(\"2: \", np.dot((1-y).T, np.log(1-pred)))\n",
    "    return (-1/m) * cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient(X, y, theta):\n",
    "    m = y.shape[0]  \n",
    "    #return X.T.dot(sigmoid(X, theta) - y)\n",
    "    #print(theta.shape)\n",
    "    #print(X.shape)\n",
    "    #print(sigmoid(X, theta).shape)\n",
    "    #print(X.T.shape)\n",
    "    #print(y.shape)\n",
    "    #print(\"mul: \", np.matmul(X.T, sigmoid(X, theta)))\n",
    "    #print(\"por si acaso: \", sigmoid(X, theta) - y)\n",
    "    #print(\"mul2: \", np.matmul(X.T, sigmoid(X, theta) - y))\n",
    "    return (1/m) * np.matmul(X.T, sigmoid(X, theta) - y)\n",
    "\n",
    "def gradient_descent( X, y, theta, nb_iterations, learning_rate):\n",
    "    '''Return the final theta vector and array of cost history over nro of iterations'''\n",
    "    #print(\"nb_it\")\n",
    "    #print(nb_iterations)\n",
    "    m = y.shape[0]\n",
    "    cost_history = np.zeros(nb_iterations)\n",
    "    for i in range(nb_iterations):\n",
    "        theta = theta - np.multiply(learning_rate, calculate_gradient(X, y, theta))\n",
    "        cost_history[i] = calculate_cost_function( X, y, theta) \n",
    "    return theta, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one vs all\n",
    "#one vs one\n",
    "def calculate_accuracy(X, y, theta):\n",
    "    #fit\n",
    "    #opt_weights = fmin_tnc(func=calculate_cost_function, x0=theta,fprime=gradient_descent,args=(X, y.flatten()))\n",
    "    #parameters = opt_weights[0]\n",
    "    #predict\n",
    "    #theta = parameters[:, np.newaxis]\n",
    "    predict = sigmoid(X, theta)\n",
    "    #print(\"predict: \",predict)\n",
    "    probab_threshold = 0.5  \n",
    "    predicted_classes = (predict >= probab_threshold)\n",
    "    result = np.logical_xor(np.logical_not(predicted_classes), y)\n",
    "    return np.sum(result) / y.shape[0]\n",
    "\n",
    "    #predicted_classes = predicted_classes.flatten()\n",
    "    #print(\"predict_classes: \",predicted_classes)\n",
    "    #accuracy = np.mean(predicted_classes == y)\n",
    "    #return accuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optional_create_training_test(data):\n",
    "    np.random.shuffle(data)\n",
    "    col = data.shape[1]-1\n",
    "    k = len(data)\n",
    "    X_train = data[:int((60* k) / 100), :col]\n",
    "    y_train = data[:int((60* k) / 100), col]\n",
    "    X_test = data[int((60* k) / 100):, :col]\n",
    "    y_test = data[int((60* k) / 100):, col]\n",
    "        \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_y(data):\n",
    "    col = data.shape[1]-1\n",
    "    x = data[:, :col]\n",
    "    y = data[:, col]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kfolds(data, k):\n",
    "    kset = np.split(data, k)\n",
    "    #print(\"kset\", kset)\n",
    "    set_X = []\n",
    "    set_y = []\n",
    "    for ik in kset:\n",
    "        col = ik.shape[1]-1\n",
    "        x = ik[:, :col]\n",
    "        y = ik[:, col]\n",
    "        #print(\"create kfold x: \",x)\n",
    "        #print(\"create kfold y: \",y)\n",
    "        set_X.append(x)\n",
    "        set_y.append(y)\n",
    "        #print(\"set_X create kfold x: \",set_X)\n",
    "        #print(\"set_y create kfold y: \",set_y)\n",
    "    #print(\"kfold_setX: \",set_X)\n",
    "    #print(\"kfold_sety: \",set_y)\n",
    "    return set_X, set_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_theta(X):\n",
    "    #print(\"random: \",k)\n",
    "    return np.random.rand(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo:  data/diabetes.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lebana/Documents/Top IA/Practics/env/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n",
      "/home/lebana/Documents/Top IA/Practics/env/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TL|It       500      1000      1500      2000      2500      3000      3500\n",
      "0   0.01  0.300781  0.263021  0.251302  0.251302  0.238281  0.235677  0.235677\n",
      "1   0.05  0.242188  0.235677  0.239583  0.238281  0.236979  0.239583  0.239583\n",
      "2   0.10  0.238281  0.238281  0.238281  0.240885  0.239583  0.240885  0.240885\n",
      "3   0.20  0.238281  0.239583  0.240885  0.240885  0.240885  0.240885  0.242188\n",
      "4   0.30  0.239583  0.240885  0.240885  0.240885  0.242188  0.242188  0.242188\n",
      "5   0.40  0.240885  0.240885  0.242188  0.242188  0.242188  0.243490  0.243490\n",
      "Archivo:  data/heart.csv\n",
      "   TL|It       500      1000      1500      2000      2500      3000      3500\n",
      "0   0.01  0.448845  0.422442  0.402640  0.396040  0.379538  0.389439  0.386139\n",
      "1   0.05  0.392739  0.389439  0.386139  0.389439  0.386139  0.386139  0.386139\n",
      "2   0.10  0.389439  0.386139  0.386139  0.386139  0.389439  0.386139  0.389439\n",
      "3   0.20  0.389439  0.386139  0.389439  0.389439  0.389439  0.389439  0.389439\n",
      "4   0.30  0.386139  0.389439  0.389439  0.389439  0.389439  0.389439  0.389439\n",
      "5   0.40  0.386139  0.389439  0.389439  0.389439  0.389439  0.389439  0.389439\n"
     ]
    }
   ],
   "source": [
    "#EXPERIMENT I\n",
    "def experimentI():\n",
    "    files = [\"data/diabetes.csv\", \"data/heart.csv\"]\n",
    "\n",
    "    for it_file in files:\n",
    "        k = 3\n",
    "        data = read_file(it_file)\n",
    "        data = normalize_data(data.values)\n",
    "        np.random.shuffle(data)\n",
    "        #cross validation\n",
    "        #set_X_train, set_y_train, set_X_test, set_y_test = create_kfolds(data)\n",
    "        set_X, set_y = create_kfolds(data, k)\n",
    "        #set_X_train = []\n",
    "        #set_y_train = []\n",
    "        #for i in range(0,len(set_X)):\n",
    "            #X_test = np.c_[set_X[i], np.ones(set_X[i].shape[0])]        #bias\n",
    "            #y_test = set_y[i]\n",
    "            #for t in range(0,3):\n",
    "                #if t!=i:\n",
    "                    #print(\"set_X[t]: \",set_X[t])\n",
    "                    #X_train = np.c_[set_X[t], np.ones(set_X[t].shape[0])]        #bias\n",
    "                    #print(\"X_train: \",X_train)\n",
    "                    #y_train = set_y[t]\n",
    "                    #set_X_train.append(X_train)\n",
    "                    #set_y_train.append(y_train)\n",
    "\n",
    "        nb_iterations = [500,1000,1500,2000,2500,3000,3500]\n",
    "        nb_its_label = nb_iterations.copy()\n",
    "        learning_rate = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4]\n",
    "        result_tb = [learning_rate]\n",
    "        print(\"Archivo: \", it_file)\n",
    "        \n",
    "        for nb_it in nb_iterations:\n",
    "            rlearning_rate = []\n",
    "            for learn_rate in learning_rate:\n",
    "                #print(\"num_iter = \", nb_it)\n",
    "                #print(\"learn_rate = \", learn_rate)\n",
    "                accuracy_total = 0.0\n",
    "                for i in range(0,len(set_X)):\n",
    "                    X_train = np.zeros((set_X[i].shape[0], set_X[i].shape[1] - 1))\n",
    "                    y_train = np.zeros((set_X[i].shape[0], 1))\n",
    "                    X_test = np.c_[set_X[i], np.ones(set_X[i].shape[0])]        #bias\n",
    "                    y_test = set_y[i]\n",
    "                    for t in range(0,k):\n",
    "                        if t!=i:\n",
    "                            #print(\"set_X[t]: \",set_X[t])\n",
    "                            X_train = np.c_[set_X[t], np.ones(set_X[t].shape[0])]        #bias\n",
    "                            #print(\"X_train: \",X_train)\n",
    "                            y_train = set_y[t]\n",
    "                            #set_X_train.append(X_train)\n",
    "                            #set_y_train.append(y_train)\n",
    "                    theta = create_theta(X_train)\n",
    "                    theta, cost_history = gradient_descent(X_train, y_train, theta, nb_it, learn_rate)\n",
    "                    accuracy_train = calculate_accuracy(X_train, y_train, theta)\n",
    "                    #print(\"accuracy train: \",accuracy_train) \n",
    "                    cost_train = calculate_cost_function(X_train, y_train, theta)\n",
    "                    #print(\"Pesos de Gradiente descendiente: \", theta)\n",
    "                    #print(\"Cost training: \", cost_train)\n",
    "                    cost_test = calculate_cost_function(X_test, y_test, theta)\n",
    "                    accuracy_test = calculate_accuracy(X_test, y_test, theta) \n",
    "                \n",
    "                    accuracy_total += accuracy_test\n",
    "                accuracy_total /= k\n",
    "                rlearning_rate.append(accuracy_total)\n",
    "                #print(\"Pesos de Gradiente descendiente: \", theta)\n",
    "                #print(\"accuracy test: \",accuracy_test) \n",
    "                #print(\"Costo test: \", cost_test, \"\\n\")\n",
    "            result_tb.append(rlearning_rate)\n",
    "\n",
    "        m = np.asarray(result_tb)\n",
    "        pdObj = pd.DataFrame(m.T[:], columns=['TL|It','500','1000','1500','2000','2500','3000','3500']) \n",
    "        print(pdObj)\n",
    "\n",
    "experimentI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.2717391304347826\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.4143646408839779\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#EXPERIMENTO II\n",
    "#iris>0.9\n",
    "#\n",
    "def experimentII():\n",
    "    files = [\"data/diabetes.csv\", \"data/heart.csv\"]\n",
    "\n",
    "    for it_file in files:\n",
    "        data = read_file(it_file)\n",
    "        data = normalize_data(data.values)\n",
    "        #costhistory = []\n",
    "        \n",
    "        set_X_train, y_train, set_X_test, y_test = optional_create_training_test(data)\n",
    "        y_train = np.reshape(y_train, y_train.shape[0])\n",
    "        y_test = np.reshape(y_test, y_test.shape[0])\n",
    "        X_train = np.c_[set_X_train, np.ones(set_X_train.shape[0])]\n",
    "        X_test = np.c_[set_X_test, np.ones(set_X_test.shape[0])]\n",
    "        \n",
    "        theta = create_theta(X_train)\n",
    "        nb_it = 1500\n",
    "        learn_rate = 0.01\n",
    "        theta, cost_history = gradient_descent(X_train, y_train, theta, nb_it, learn_rate)\n",
    "        #print(\"set_train: \", set_X_train[j].shape)\n",
    "        #print(\"theta: \", theta.shape)\n",
    "        accuracy = calculate_accuracy(X_train, y_train, theta)\n",
    "        print('training accuracy: ', accuracy)\n",
    "        #costhistory.append(cost_history)\n",
    "        plt.plot(range(len(cost_history)), cost_history)\n",
    "        plt.show()\n",
    "        #plt.plot(range(len(costhistory)), costhistory)\n",
    "        #plt.show()          \n",
    "\n",
    "experimentII()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador multiclase UNO vs UNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPERIMENT 3 UNO vs UNO\n",
    "def experimentIIIa():\n",
    "    data = read_file(\"data/Iris.csv\")\n",
    "    data = data.sample(frac=1)\n",
    "    k = 3\n",
    "    learn_rate = 0.01\n",
    "    num_iter = 1500\n",
    "    \n",
    "    acc_test_total_vec = []\n",
    "    X, y = X_y(data.values)\n",
    "    y_values = np.unique(y)\n",
    "    \n",
    "    data_X = normalize_data(X)\n",
    "    _data = np.concatenate((data_X, y), axis=1)\n",
    "    \n",
    "    W_vec = []\n",
    " \n",
    "    data_sep_y = []\n",
    "    for i in range(y_values.shape[0]):\n",
    "        data_class = []\n",
    "        for j in range(_data.shape[0]):\n",
    "            if _data[j, _data.shape[1]-1] == y_values[i]:\n",
    "                data_class.append(_data[j])\n",
    "        data_sep_y.append(data_class)\n",
    "    set_X, set_y = create_kfolds(_data, k)\n",
    "    \n",
    "    vaccuracy_test = []\n",
    "    for l in range(y_values.shape[0]):\n",
    "        x = l+1\n",
    "        while x < y_values.shape[0]:\n",
    "            norm_data = np.concatenate((norm_data_sep_y[l], norm_data_sep_y[x]), axis=0)\n",
    "            np.random.shuffle(norm_data)\n",
    "            X, y = Separar_X_y(norm_data)\n",
    "            X_train, X_test = Crear_Entrenamiento_Prueba(X)\n",
    "            y_train, y_test = Crear_Entrenamiento_Prueba(y)\n",
    "\n",
    "            y_train = np.reshape(y_train, y_train.shape[0])\n",
    "            y_test = np.reshape(y_test, y_test.shape[0])\n",
    "\n",
    "            X_train = np.c_[X_train, np.ones(X_train.shape[0])]     #bias\n",
    "            X_test = np.c_[X_test, np.ones(X_test.shape[0])]        #bias\n",
    "\n",
    "            W = Crear_Pesos(X_train)\n",
    "            X_train = X_train.astype(float)\n",
    "            y_train = y_train == y_values[x]\n",
    "            y_train = y_train.astype(int)\n",
    "            W, costs = Gradiente_Descendiente(X_train, y_train, W, num_iter, learn_rate)\n",
    "            W_vec.append(W)\n",
    "            X_test = X_test.astype('float')\n",
    "            y_test = y_test == y_values[x]\n",
    "            y_test = y_test.astype(int)\n",
    "            acc_test = Calcular_Accuraccy(X_test, y_test, W)\n",
    "            vaccuracy_test.append(acc_test)\n",
    "\n",
    "            x += 1\n",
    "\n",
    "\n",
    "    print(\"Clasificación multiclase 'uno vs uno'\")\n",
    "    print(\"Accuracy en los datos de prueba para 'Iris-setosa vs Iris-versicolor' 'Iris-setosa vs Iris-virginica' 'Iris-versicolor vs Iris-virginica' respectivamente:\")\n",
    "    print(acc_test_vec)\n",
    "experimentIII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-c0b78aa164d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mresult_tb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvaccuracy_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mexperimentIII\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-114-c0b78aa164d0>\u001b[0m in \u001b[0;36mexperimentIII\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#y is string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mset_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_kfolds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "#EXPERIMENT 3 UNO vs TODOS\n",
    "def experimentIIIb():\n",
    "    #col = file[\"Species\"].value_counts()\n",
    "    #print(col[0])\n",
    "    data = read_file(\"data/Iris.csv\")\n",
    "    data = data.sample(frac=1)\n",
    "    k=3\n",
    "    nb_it = 1500\n",
    "    learn_rate = 0.01\n",
    "    \n",
    "    X, y = X_y(data.values)\n",
    "    \n",
    "    data_X = normalize_data(X)\n",
    "    print(data_X.shape)\n",
    "    print(y.shape)\n",
    "    _data = np.concatenate((data_X, y), axis=1) #y is string\n",
    "    set_X, set_y = create_kfolds(_data, k)\n",
    "    \n",
    "    y_values = np.unique(set_y)\n",
    "    vaccuracy_total = []\n",
    "    \n",
    "    for iy in range(y_values.shape[0]):\n",
    "        accuracy_total = 0.0\n",
    "        for i in range(0,len(set_X)):\n",
    "            X_train = np.zeros((set_X[i].shape[0] * (k-1), set_X[i].shape[1] - 1))\n",
    "            y_train = np.zeros((set_X[i].shape[0], 1))\n",
    "            X_test = np.c_[set_X[i], np.ones(set_X[i].shape[0])]        #bias\n",
    "            y_test = set_y[i] == y_values[iy]\n",
    "            for t in range(0,k):\n",
    "                if t!=i:\n",
    "                    #print(\"set_X[t]: \",set_X[t])\n",
    "                    X_train = np.c_[set_X[t], np.ones(set_X[t].shape[0])]        #bias\n",
    "                    #print(\"X_train: \",X_train)\n",
    "                    y_train = set_y[t] == y_values[iy]\n",
    "                    #set_X_train.append(X_train)\n",
    "                    #set_y_train.append(y_train)\n",
    "            theta = create_theta(X_train)\n",
    "            theta, cost_history = gradient_descent(X_train, y_train, theta, nb_it, learn_rate)\n",
    "            accuracy_train = calculate_accuracy(X_train, y_train, theta)\n",
    "                    #print(\"accuracy train: \",accuracy_train) \n",
    "            cost_train = calculate_cost_function(X_train, y_train, theta)\n",
    "                    #print(\"Pesos de Gradiente descendiente: \", theta)\n",
    "                    #print(\"Cost training: \", cost_train)\n",
    "            cost_test = calculate_cost_function(X_test, y_test, theta)\n",
    "            accuracy_test = calculate_accuracy(X_test, y_test, theta) \n",
    "                \n",
    "            accuracy_total += accuracy_test\n",
    "        accuracy_total /= k\n",
    "        vaccuracy_total.append(accuracy_total)\n",
    "        print(\"Pesos de Gradiente descendiente: \", theta)\n",
    "        print(\"Costo test: \", cost_test, \"\\n\")\n",
    "    result_tb.append(vaccuracy_total)\n",
    "\n",
    "experimentIII()              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentI()\n",
    "experimentII()\n",
    "experimentIII()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
