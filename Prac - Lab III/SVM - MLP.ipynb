{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import utils\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.metrics import jaccard_score\n",
    "import random\n",
    "\n",
    "def read_file(filename):\n",
    "    return pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    data = data.astype('float64')\n",
    "    mean = np.mean(data)\n",
    "    st = np.std(data)\n",
    "    return (data - mean)/st   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/ (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(X, y, W):\n",
    "    \"\"\" accerted values respect to predict\"\"\"\n",
    "    accerted = 0.0\n",
    "    num = 14\n",
    "    total = num\n",
    "    for i in range(0, num): #place to 14 can be X.shape[0]\n",
    "        temp = W.values()[len(W)-1]\n",
    "        temp = int(np.round_(temp[i]))\n",
    "        if temp == y[i]:\n",
    "            accerted += 1\n",
    "    return accerted/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_y(data):\n",
    "    col = data.shape[1]-1\n",
    "    x = data[:, :col]\n",
    "    y = data[:, col:]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kfolds(data, k):\n",
    "    np.random.shuffle(data)\n",
    "    size_fold = int(data.shape[0] / k)\n",
    "    _sz_fold = int(data.shape[0] % k)\n",
    "    data = data[:data.shape[0]-_sz_fold,:]\n",
    "    kfolds = []\n",
    "    idx_row = 0\n",
    "    for i in range(k):\n",
    "        X, y = X_y(data[idx_row:idx_row+size_fold, :])\n",
    "        kfolds.append({\"X\": X, \"y\" : y})\n",
    "        idx_row += size_fold\n",
    "    return kfolds, size_fold\n",
    "\n",
    "def kfolds_cross_validation(data, k):\n",
    "    for i in range(0, k):\n",
    "        temp_test_data = k_folds[i]\n",
    "        temp_train_data = np.delete(k_folds, i, axis=0)\n",
    "        temp_train_data = temp_train_data.reshape(-1, temp_test_data.shape[1])\n",
    "        np.random.shuffle(temp_train_data)\n",
    "\n",
    "        x_train_set, y_train_set = get_x_y_data(temp_train_data)\n",
    "        y_train_set = y_train_set.reshape(y_train_set.shape[0])\n",
    "\n",
    "        x_test_set, y_test_set = get_x_y_data(temp_test_data)\n",
    "        y_test_set = y_test_set.reshape(y_test_set.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost_function(X, y, W):\n",
    "    m = X.shape[0]\n",
    "    pred = sigmoid(X)\n",
    "    print('pred', pred)\n",
    "    cross_entropy = np.sum( (y * np.log(pred)) + ((1-y) * np.log(1-pred)) )\n",
    "    #print(\"1: \",np.dot(y.T, np.log(pred)))\n",
    "    #print(\"2: \", np.dot((1-y).T, np.log(1-pred)))\n",
    "    return (-1/m) * cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dS(D):\n",
    "    return sigmoid(D)*(1.0-sigmoid(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, W):\n",
    "    A = {}\n",
    "    i=0\n",
    "    for key, value in W.items():\n",
    "        sumt = np.matmul(X, value)\n",
    "        y = sigmoid(sumt)\n",
    "        A.setdefault(i, y)\n",
    "        #other way: A['activation'+str(i)]=y\n",
    "        i = i+1\n",
    "        \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(X, A, y, W, learning_rate):\n",
    "    newW = {}\n",
    "    \n",
    "    #last layer\n",
    "    last_output = (A.values()[len(A)-1])\n",
    "    real_error = y - last_output\n",
    "    #print('real error: ', real_error)\n",
    "    #delta = last_output * (1-last_output) * (1-last_output)\n",
    "    delta = real_error * dS(1-last_output) \n",
    "    \n",
    "    for key, value in W.items():\n",
    "        #print('val: ', value)\n",
    "        #print('val', value.shape[0], value.shape[1])\n",
    "        mult = learning_rate * A[key] * delta\n",
    "        result = value + mult\n",
    "        #print(result)\n",
    "        newW.setdefault(key, result)\n",
    "    return newW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient(X, y, W):\n",
    "    m = y.shape[0]  \n",
    "    return (1/m) * np.matmul(X.T, sigmoid(X, W.values()) - y)\n",
    "\n",
    "def gradient_descent( X, y, W, nb_iterations, learning_rate):\n",
    "    cost_history = np.zeros(nb_iterations)\n",
    "    for i in range(nb_iterations):\n",
    "        error_epoch = 0.0\n",
    "        A = {}\n",
    "        for j in range(0, X.shape[0]):\n",
    "                A = forward(X[j], W)\n",
    "                last_errors = np.divide(np.power(y - W.values()[len(W)-1], 2), 2)\n",
    "                error_epoch += np.sum(last_errors)\n",
    "                backward(X[j], A, y[j], W, learning_rate)\n",
    "        #cost_history[i] = calculate_cost_function( X, y, W)\n",
    "    return W, cost_history\n",
    "                \n",
    "def _gradient_descent( X, y, W, nb_iterations, learning_rate):\n",
    "    '''Return the final theta vector and array of cost history over nro of iterations\n",
    "    nb_iterations: or epochs\n",
    "    '''\n",
    "    m = y.shape[0]\n",
    "    cost_history = np.zeros(nb_iterations)\n",
    "    A = {}\n",
    "    for i in range(nb_iterations):\n",
    "        #prediction = X.dot(W.values())\n",
    "        \n",
    "        print('W.values()', W.values()[i])\n",
    "        prediction = np.matmul(X,W.values()[i])\n",
    "        print('prediction ',prediction.shape)\n",
    "        print('y ', y.shape)\n",
    "        \n",
    "        if W.values()[len(W)-1]:\n",
    "            prediction = np.matmul(X,W.values()[i])\n",
    "            print(prediction - y)\n",
    "            ro = (X.dot(prediction - y))\n",
    "            print('ro ', ro)\n",
    "            \n",
    "            r = ((1/m) * learning_rate * (X.T.dot(prediction - y)))\n",
    "        print('r ', r)\n",
    "        W = W.values() - r\n",
    "        #cost_history[i] = calculate_cost_function( X, y, W) \n",
    "    return W, cost_history   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optional_create_training_test(data):\n",
    "    np.random.shuffle(data)\n",
    "    col = data.shape[1]-1\n",
    "    k = len(data)\n",
    "    X_train = data[:int((60* k) / 100), :col]\n",
    "    y_train = data[:int((60* k) / 100), col]\n",
    "    X_test = data[int((60* k) / 100):, :col]\n",
    "    y_test = data[int((60* k) / 100):, col]\n",
    "        \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def create_training_test(data):\n",
    "    num_rows = data.shape[0]\n",
    "    train_percentage = 0.6\n",
    "    row_split_data = int(num_rows * train_percentage)\n",
    "    training, test = data[:row_split_data, :], data[row_split_data:, :]\n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_W(X, nb_neuron):\n",
    "    return np.random.rand(X.shape[1], nb_neuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENT I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Archivo:  Iris.csv\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Iris-setosa'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-49674ac46866>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdObj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[0mexperimentI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-36-49674ac46866>\u001b[0m in \u001b[0;36mexperimentI\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                             \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount_sz_fold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcount_sz_fold\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msz_fold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfolds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                             \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount_sz_fold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcount_sz_fold\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msz_fold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfolds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m                             \u001b[0mcount_sz_fold\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msz_fold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Iris-setosa'"
     ]
    }
   ],
   "source": [
    "def experimentI():\n",
    "    files = [\"Iris.csv\"]\n",
    "    learning_rate = 0.2\n",
    "    epochs = 100 #nb_iterations\n",
    "    hidde_layers = [1, 2, 3]\n",
    "    nb_neurons = [5, 6, 7]\n",
    "    k = 3\n",
    "    \n",
    "    for it_file in files:\n",
    "        print(\"Archivo: \", it_file)\n",
    "        result_tb = [hidde_layers]\n",
    "        data = read_file(it_file)\n",
    "        X, y = X_y(data.values)\n",
    "        data_X = normalize_data(X)\n",
    "        data = np.concatenate((data_X, y), axis=1)\n",
    "        kfolds, sz_fold = create_kfolds(data, k)\n",
    "        \n",
    "            \n",
    "        for layer in hidde_layers:\n",
    "            W = {}\n",
    "            hlayers = []\n",
    "            for nb_neuron in nb_neurons:\n",
    "                accuracy_test_total = 0.0\n",
    "                countw = 0\n",
    "                for i in range(k):\n",
    "                    X_train = np.zeros((sz_fold * (k-1), data.shape[1] - 1))\n",
    "                    y_train = np.zeros((sz_fold * (k-1), 1))\n",
    "                    X_test = np.zeros((sz_fold, data.shape[1] - 1))\n",
    "                    y_test = np.zeros((sz_fold, 1))\n",
    "                    count_sz_fold = 0\n",
    "                    for j in range(k):\n",
    "                        if j == i:\n",
    "                            X_test = kfolds[i]['X']\n",
    "                            y_test = kfolds[i]['y']\n",
    "                        else:\n",
    "                            X_train[count_sz_fold:count_sz_fold+sz_fold, :] = kfolds[j]['X']\n",
    "                            y_train[count_sz_fold:count_sz_fold+sz_fold, :] = kfolds[j]['y']\n",
    "                            count_sz_fold += sz_fold\n",
    "\n",
    "                    y_train = np.reshape(y_train, y_train.shape[0])\n",
    "                    y_test = np.reshape(y_test, y_test.shape[0])\n",
    "\n",
    "                    X_train = np.c_[X_train, np.ones(X_train.shape[0])]     #bias\n",
    "                    X_test = np.c_[X_test, np.ones(X_test.shape[0])]        #bias\n",
    "                    \n",
    "                    for i in range(layer):\n",
    "                        W.setdefault(countw, create_W(X_train, nb_neuron))\n",
    "                        countw = countw + 1\n",
    "                    #capa salida\n",
    "                    W.setdefault(countw, create_W(X_train, 1))\n",
    "                    countw = countw + 1\n",
    "                    \n",
    "                    W, cost_history = gradient_descent(X_train, y_train, W, epochs, learning_rate)\n",
    "                    accuracy_test = calculate_accuracy(X_test, y_test, W)\n",
    "                    accuracy_test_total += accuracy_test\n",
    "                    \n",
    "                accuracy_test_total /= k\n",
    "                hlayers.append(\"%.4f\" % accuracy_test_total)\n",
    "            result_tb.append(hlayers)\n",
    "\n",
    "        m = np.asarray(result_tb)\n",
    "        pdObj = pd.DataFrame(m.T[:], columns=['HL|N','5','6','7']) \n",
    "        print(pdObj)\n",
    "\n",
    "experimentI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENT II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Archivo:  data/heart.csv\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data/heart.csv' does not exist: b'data/heart.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-0e0b0b5554f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mpdObj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'C|kernel'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"linear\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"poly\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rbf\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdObj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m \u001b[0mexperimentII\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-0e0b0b5554f0>\u001b[0m in \u001b[0;36mexperimentII\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mit_file\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Archivo: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mdata_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-dbec6ea14311>\u001b[0m in \u001b[0;36mread_file\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data/heart.csv' does not exist: b'data/heart.csv'"
     ]
    }
   ],
   "source": [
    "#EXPERIMENTO II\n",
    "#iris>0.9\n",
    "\n",
    "def experimentII():\n",
    "    files = [\"data/heart.csv\", \"data/Iris.csv\"]\n",
    "    kind_kernel = [\"linear\", \"poly\", \"rbf\"]\n",
    "    setC = [3,5,7]\n",
    "    k = 3\n",
    "    gamma = 1\n",
    "    for it_file in files:\n",
    "        print(\"Archivo: \", it_file)\n",
    "        data = read_file(it_file)\n",
    "        X, y = X_y(data.values)\n",
    "        data_X = normalize_data(X)\n",
    "        data = np.concatenate((data_X, y), axis=1)\n",
    "        kfolds, sz_fold = create_kfolds(data, k)\n",
    "        y_val = np.unique(y) # values y\n",
    "        \n",
    "        result_tb = [setC]\n",
    "        \n",
    "        for kind in kind_kernel:\n",
    "            _setC = []\n",
    "            for C in setC:\n",
    "                accuracy = 0.0\n",
    "                \n",
    "                for l in range(y_val.shape[0]):\n",
    "                    for i in range(k):\n",
    "                        X_train = np.zeros((sz_fold * (k-1), data.shape[1] - 1))\n",
    "                        y_train = np.zeros((sz_fold * (k-1), 1))\n",
    "                        X_test = np.zeros((sz_fold, data.shape[1] - 1))\n",
    "                        y_test = np.zeros((sz_fold, 1))\n",
    "                        count_sz_fold = 0\n",
    "                        for j in range(k):\n",
    "                            if j == i:\n",
    "                                X_test = kfolds[i]['X']\n",
    "                                y_test = kfolds[i]['y']\n",
    "                            else:\n",
    "                                X_train[count_sz_fold:count_sz_fold+sz_fold, :] = kfolds[j]['X']\n",
    "                                y_train[count_sz_fold:count_sz_fold+sz_fold, :] = kfolds[j]['y'] == y_val[l]\n",
    "                                count_sz_fold += sz_fold\n",
    "\n",
    "                        y_train = np.reshape(y_train, y_train.shape[0])\n",
    "                        y_test = np.reshape(y_test, y_test.shape[0])\n",
    "\n",
    "                        X_train = np.c_[X_train, np.ones(X_train.shape[0])]     #bias\n",
    "                        X_test = np.c_[X_test, np.ones(X_test.shape[0])]        #bias\n",
    "\n",
    "                        lab_enc = preprocessing.LabelEncoder()\n",
    "                        training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "                        \n",
    "                        tlab_enc = preprocessing.LabelEncoder()\n",
    "                        testing_scores_encoded = tlab_enc.fit_transform(y_test)\n",
    "                        \n",
    "                        if kind == 'linear':\n",
    "                            #LINEAL\n",
    "                            svm_reg = SVC(kernel= kind, C=C)\n",
    "                            svm_reg.fit(X_train, training_scores_encoded)\n",
    "                            accuracy_linear = svm_reg.score(X_test, testing_scores_encoded)\n",
    "                            accuracy = accuracy_linear\n",
    "                            #print('accuracy linear: ',accuracy_linear)\n",
    "                        elif kind == 'poly':\n",
    "                            #POLINOMIAL\n",
    "                            svm_reg = SVC(kernel= kind, C=C, degree=3, gamma=gamma)\n",
    "                            svm_reg.fit(X_train, training_scores_encoded)\n",
    "                            accuracy_poly = svm_reg.score(X_test, testing_scores_encoded)\n",
    "                            accuracy = accuracy_poly\n",
    "                            #print('accuracy polinomial: ',accuracy_poly)\n",
    "                        else:\n",
    "                            #GAUSSIANO\n",
    "                            svm_reg = SVC(kernel= kind, C=C, gamma=gamma)\n",
    "                            svm_reg.fit(X_train, training_scores_encoded)\n",
    "                            accuracy_gauss = svm_reg.score(X_test, testing_scores_encoded)\n",
    "                            accuracy = accuracy_gauss \n",
    "                            #print('accuracy gaussiano: ',accuracy_gauss)\n",
    "\n",
    "                _setC.append(\"%.4f\" % accuracy)\n",
    "            result_tb.append(_setC)\n",
    "\n",
    "        m = np.asarray(result_tb)\n",
    "        pdObj = pd.DataFrame(m.T[:], columns=['C|kernel',\"linear\", \"poly\", \"rbf\"]) \n",
    "        print(pdObj)          \n",
    "experimentII()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}